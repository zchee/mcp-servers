{
  "id": "10265",
  "year": "2021",
  "url": "https://developer.apple.com/videos/play/wwdc2021/10265/",
  "title": "Immerse your app in Spatial Audio",
  "speakers": [],
  "duration": "",
  "topics": [
    "Audio & Video"
  ],
  "hasTranscript": true,
  "hasCode": true,
  "transcript": {
    "fullText": "♪ Bass music playing ♪  ♪ Simon Goldrei: Hello! In this session, we'll explore how to immerse your app in spatial audio.\n\nI'm Simon and I'm part of the streaming media team here at Apple.\n\nDo you want to offer your customers, and differentiate your service, with the experience of a movie theater? Would you like to offer immersive audio with rendering of multipoint audio sources that provides that sense of being there? Can we do all this from the convenience of the mobile device in our customer's pocket? In this session, we're going to explore spatial audio and how to deliver it with the Core AVFoundation playback APIs and WebKit.\n\nWe've got a full agenda.\n\nTogether we'll cover what is spatial audio by contrasting it to existing technology we're familiar with.\n\nThen we'll enumerate the technologies and treatments that the feature offers.\n\nIn the second half, I'll introduce API and highlight different treatments that are applied.\n\nNext up, we'll review the levels of support for spatial audio in prior releases so that you can target features appropriately.\n\nI'll also reveal what's new this year in our fall 2021 OS releases.\n\nThen to top it all off, we'll end with a demo.\n\nI'm excited to share that with you.\n\nYou're in for a treat! To understand what is spatial audio, let's start by considering classic stereo.\n\nBe it headphones or stereo speaker arrangements of yesteryear, the soundstage we perceive is rather limited.\n\nWe don't hear sounds from behind us, directly in front, or above us.\n\nIt's missing lifelike, positional reproduction.\n\nAnd in the case of headphones, the sound emanates from tiny speakers in, or on, our heads; we call this an in-head experience.\n\nAs we naturally move our heads while watching a movie, those tiny speakers move with us.\n\nThis is not a theater-like experience, but this is where spatial audio can help.\n\nSpatial audio offers a theater-like experience.\n\nIt's a psychoacoustic technology that has the effect of producing a compelling virtual soundstage.\n\nIt works best with multichannel content but it also offers a compelling experience for stereo content as well.\n\nFinally, spatial audio support is offered for audiovisual and audio-only media sources.\n\nBest of all, it works with a variety of Apple products your customers already have.\n\nWe made it simple to bring the spatial audio experience to your customers.\n\nAs I just alluded to, the best way to enjoy spatial audio in your applications is to provide multichannel audio.\n\nThat experience is most adaptive to the customer's environment when providing HLS variants that reference multichannel audio alternates.\n\nIn fact, you may already have in your content library multichannel audio source media.\n\nSimply publishing this will enable, by default, spatial audio in your application.\n\nThere's absolutely no software change needed.\n\nMultichannel audio tracks in regular media files -- and WebKit's MSE in the fall 2021 releases -- also benefit from limited support that I'll detail later.\n\nLet me tell you about media experiences you can now expect to create.\n\nThere's so many experiences you can now recreate with spatial audio.\n\nYou can deliver music that surrounds us, that feels like being at the concert.\n\nYou can build full-motion video games with interactive scenes that take gamers on their own immersive adventures.\n\nBut how does this technology work? When spatial audio is used, the virtual soundstage is static.\n\nThe soundstage doesn't move with casual head movement, unlike we saw earlier with stereo.\n\nWhat we get is the same audible effect and feeling we expect from the theater.\n\nThis effect is possible both from the built-in speakers in many of our products and now is also available in select headphone products.\n\nWhen spatial-capable headphones are used, measurements from inertial measurement units in the playback device are compared with similar measurements in the headphones to determine the customer's head pose.\n\nThis is used to dynamically alter the audio rendering to maintain that static soundstage effect.\n\nThe result is a feeling like the audio is emanating from the original placement around the camera, or listener, for an out-of-head experience.\n\nIt even works on a turning bus or a banking airplane.\n\nWe also offer a technique to up-mix stereo sources to reproduce a 5.1 channel experience.\n\nWe provide this feature to offer spatial audio along with your existing library of stereo content.\n\nFor supported headphones, it is the default stereo treatment in our fall 2021 releases.\n\nWe also use this treatment implicitly to make spatial audio even more compelling for you to adopt and offer, because right about now, you're probably thinking that distributing multichannel audio might impede the visual quality of your media.\n\nAfter all, multichannel audio is much higher bitrate than the stereo AAC renditions you offer today.\n\nHow can you possibly fit both in a constrained network bandwidth environment? This a real problem.\n\nWe solved this by making the spatial audio experience adaptive to your customer's bandwidth.\n\nWhen bandwidth is insufficient to deliver a high-quality audiovisual experience, the audio seamlessly degrades to a stereo, up-mixed -- but a still spatial -- treatment.\n\nHead-tracking, if offered before the transition, is maintained.\n\nSoon after, when bandwidth reliably recovers, the full multichannel spatial treatment is restored.\n\nWith this adaptive spatial audio experience, it is ever more important to both normalize the volume levels between stereo and multichannel renditions.\n\nIn addition, please provide DRC -- Dynamic Range Control -- and dialnorm metadata in your media encodings as is appropriate.\n\nThis is described in more detail in the HLS Authoring Specification available at developer.apple.com.\n\nLet's take a look now at the interfaces you can use to tailor the spatial audio experience.\n\nTo customize the default spatial audio experience in your application -- be it via AVPlayerItem or now, AVSampleBufferAudioRenderer -- you specify one of four AVAudioSpatializationFormats.\n\nThese are to permit the spatialization of mono and stereo, multichannel, and the combination of the last two -- that is mono, stereo, and multichannel source audio formats.\n\nYou can also specify zero to inhibit audio spatialization.\n\nDo note that our platforms provide system-level controls for customers to tailor the experience further, depending on the type of audio route, through Control Center and Bluetooth settings.\n\nWe take one of these four values and set it on the allowedAudioSpatialization Formats property on an AVPlayerItem and now, new in our fall 2021 releases, an AVSampleBufferAudioRenderer.\n\nNow, you may be wondering, how do you use AVFoundation APIs to discover if an audio route supports spatial audio? How do you know if you should deliver multichannel audio to your AVSampleBufferAudioRenderer instance? Well, in the fall 2021 releases, we're introducing a property that indicates this on an AVAudioSessionPortDescription.\n\nIn addition, on AVAudioSession, we're introducing a mechanism for you to advertise to the system that your application is able to offer multichannel audio.\n\nThis indication is shown if the customers haven't enabled the spatial audio treatment in Control Center or Bluetooth preferences.\n\nNote that if your application uses AVPlayer, these indications are managed for you.\n\nThe isSpatialAudioEnabled property indicates that the port is capable of both rendering spatial audio and that the customer permits it.\n\nYou are encouraged to observe route change notifications and to check isSpatialAudioEnabled at each event.\n\nSimilarly, AVAudioSession will emit a spatialPlaybackCapabilities ChangedNotification when the customer alters the spatial preferences in Control Center and Bluetooth settings.\n\nAs a convenience, this notification carries information about the state of spatial audio enablement.\n\nUse the AVAudioSession SpatialAudioEnabledKey to retrieve the state as it pertains to this notification.\n\nFinally, to indicate to the system that your software or service can provide multichannel content, you call the function setSupportsMultichannelContent with your intent.\n\nThis is used to relay to the customer that a spatial experience is available if network conditions permit and if the treatment is enabled.\n\nLet's now survey the feature support across the last three release years.\n\nIn macOS Catalina, iOS and iPad OS 13, spatial audio is offered via built-in speakers with AVPlayerItem and the WebKit video tag by specifying any URL with an http scheme.\n\nIt is available to customers with 2018 and later year model MacBook, iPhone, and iPad Pro product lines.\n\nThe default is to offer spatialization by selecting multichannel audio renditions where available.\n\nIn macOS Big Sur, iOS and iPad OS 14, we introduced support for the AirPods Pro and AirPods Max head-track-capable headphones.\n\nSpatialization capabilities via these accessories is offered to 2016 and later iPhone- and iPad-paired devices.\n\nThe default remains to offer spatialization by selecting multichannel audio renditions where available.\n\nThat brings us to the all-new support in macOS Monterey, iOS, iPadOS, and now, tvOS 15.\n\nHere we offer support via AVPlayerItem, AVSampleBufferAudioRenderer, and limited WebKit support for W3C Media Source Extensions, MSE.\n\nThe MSE path offers no interface to tailor the spatialization experience.\n\nHowever, there does exist an interface to detect the availability of spatial audio support via the AudioConfiguration dictionary within the Media Capabilities API set.\n\nThe default in these releases is to offer audio spatialization by default for all of mono, stereo, and multichannel sources where available and conditions permit.\n\nFor audio-only presentations, including all AVSampleBuffer AudioRenderer uses, only multichannel audio renditions are offered the treatment by default.\n\nNow that we know what spatial audio is and how to use it, we've got something really special lined up for you today.\n\nWe're going to show you how you can use spatial audio in your software and services to help tell stories in new, creative ways.\n\nLet's have a listen! ♪ Upbeat music playing ♪ < Uh-oh. Let's try that again.\n\nUm... Uh... Cupertino? We have a problem.\n\nOffscreen voice: What is it this time? Simon:  I know. I know. Anything? Offscreen whisper: Sorry, Simon. Simon: No? Offscreen whisper: It's not going to work.\n\nSimon: Really? Offscreen whisper: I know...\n\nSimon:  Bugger it. All right. All right. All right.\n\nSo we made this really great demo to demonstrate all the cool things you can do with spatial audio but... you know...\n\nit seems like this isn't happening today.\n\nLook.\n\nWe're going to try something.\n\nI can't show you this video but what if I could, um...\n\n...describe it? OK. So I don't know where you are right now, but I want you to close your eyes and let's imagine we're in a WWDC hall.\n\nYou know what that sounds like, right? What that feels like? Picture it in your mind.\n\nPicture the stage and the big screen.\n\nWe're just about to dim the lights and start playing this video.\n\nOi! You! Dim the lights.\n\nWe're high in the sky above San Francisco.\n\nWhooshing from the bay, down through the tall buildings.\n\nThe wind is rushing all around us, and then we're zooming out of the city and down the peninsula, all the way to Apple Park.\n\nWe soar into the park and you see somebody with amazing hair duck as we fly past.\n\nHe shouts, \"Slow down!\" which has this really cool left-to-right Doppler effect.\n\nSlow down! And we're flying through the Apple orchard now.\n\nFeel the whoosh of the trees.\n\nWe find ourselves at the pond for a moment of peace and tranquility.\n\nWhispered voice: I'm honestly not sold on spatial audio.\n\nSimon: And then, we're on the move again, whooshing over the birds until we reach the big glass doors of Caffè Macs sliding across the smooth terrazzo floor until we find this woman.\n\nShe's eating a pizza with her iPad propped up on the table, totally absorbed in this movie that's really, really tense.\n\nIt's this teeming jungle at the earliest hours of dusk.\n\nThe audio is literally -- no really! It's -- It's pulling us into the scene.\n\nWhispered voice: He's doing a great job describing this demo.\n\nI almost feel like I'm there. It's so vivid.\n\nSimon: ...and distant monkey calls. But suddenly it gets eerie... ...and all the creatures go quiet.\n\nAll we can hear is the rustling of leaves.\n\nThen a c-c-c-crash as a tree falls.\n\nSomething is coming! Something big! Thump. Thump. Thump.\n\nWe can hear our heart beating, right in the chest.\n\nAnd then... silence.\n\nWe're about to relax when...\n\na dinosaur bursts through the trees right across from us! And we look up, straight into its gaping maw!   Voice over PA: That's a wrap on 42...\n\nSimon: We pull back to reveal we're on a film set.\n\nMan: I'm not sure I love that lighting...\n\nSimon: The dinosaur has stopped moving and a crew of people have appeared to clear the set.\n\nWoman: Go for Kelly.\n\nVoice over radio: You got a 20 on actors? Woman: Yeah. They're in makeup watching the launch. Going off comms.\n\nWoman: Are you coming? Simon: We follow two of them into a trailer to watch today's space launch -- streaming, of course, in surround audio.\n\nThe audience is holding their breath but we move through them and into the TV.\n\nWoman: Go for launch. Man: Good across the board.\n\nSimon: And now we're inside the capsule.\n\nWoman: Let's put the pedal to the floor.\n\nSimon: The rocket ignites! Woman:  Here we go! Express service to the moon! Next stop, Tranquility.\n\nMan: All still good. Booster separation in three, two, one...\n\nClean and smooth. Simon: The second stage of the rocket has dropped away, and we drop with it...\n\n...and follow the stage as it falls back to Earth, getting faster and faster. We're dropping through the atmosphere now, back towards the ground.\n\nTowards something.\n\nA big jet plane.\n\nGetting bigger, and bigger, and --   Woman on PA: Good morning, folks.\n\nThis is your captain speaking from the flight deck.\n\n...our descent towards our final destination today.\n\nShouldn't be more...\n\nSimon:  It's beautiful!  Well, so, uh... that was fun.\n\nLet's summarize what we saw and heard.\n\nWe discovered how easy it is to offer our customers a spatial audio experience.\n\nIn fact, you may not need to do anything to your application to take advantage of spatial audio.\n\nJust by offering multichannel audio in your HLS variant playlists is often sufficient.\n\nRemember, it is important to normalize volume levels between stereo and multichannel renditions, and to include DRC metadata.\n\nFinally, we've seen how you can offer spatial audio to a wide customer base across the last three years of OS releases.\n\nIn our related sessions, you can learn how to discover if your HLS resources have multichannel audio.\n\nLearn all about that as you explore HLS variants in AVFoundation.\n\nI hope you've enjoyed this session as much as the team here and I have.\n\nWe hope you'll immerse yourself, and your app, in spatial audio and enjoy the rest of WWDC 2021.\n\nThank you.\n\n♪",
    "segments": []
  },
  "codeExamples": [
    {
      "timestamp": "6:55",
      "title": "Spatialization Formats",
      "language": "swift",
      "code": "public struct AVAudioSpatializationFormats : OptionSet {\n\n    public init(rawValue: UInt)\n\n    \n    public static var monoAndStereo: AVAudioSpatializationFormats { get }\n\n    public static var multichannel: AVAudioSpatializationFormats { get }\n\n    public static var monoStereoAndMultichannel: AVAudioSpatializationFormats { get }\n}"
    },
    {
      "timestamp": "7:21",
      "title": "AVPlayerItem and AVSampleBufferAudioRenderer",
      "language": "swift",
      "code": "@available(macOS 11.0, *)\nvar allowedAudioSpatializationFormats: Int32"
    },
    {
      "timestamp": "8:21",
      "title": "Spatial audio availability",
      "language": "swift",
      "code": "@available(iOS 6.0, *)\nclass AVAudioSessionPortDescription : NSObject {\n\n  @available(iOS 15.0, *)\n  var isSpatialAudioEnabled: Bool { get }\n\n }"
    },
    {
      "timestamp": "8:35",
      "title": "Spatial audio availability",
      "language": "swift",
      "code": "extension AVAudioSession {\n  @available(iOS 15.0, *)\n  class let spatialPlaybackCapabilitiesChangedNotification: NSNotification.Name\n}\n\n@available(iOS 15.0, *)\nlet AVAudioSessionSpatialAudioEnabledKey: String"
    },
    {
      "timestamp": "9:01",
      "title": "Control center integration",
      "language": "swift",
      "code": "extension AVAudioSession {\n  @available(iOS 15.0, *)\n  func setSupportsMultichannelContent(_ inValue: Bool) throws\n  @available(iOS 15.0, *)\n  var supportsMultichannelContent: Bool { get }\n}"
    }
  ],
  "resources": {
    "resourceLinks": [
      {
        "title": "Design",
        "url": "https://developer.apple.com/design/"
      },
      {
        "title": "Core Audio",
        "url": "https://developer.apple.com/documentation/CoreAudio"
      },
      {
        "title": "Documentation",
        "url": "https://developer.apple.com/documentation/"
      },
      {
        "title": "Forums",
        "url": "https://developer.apple.com/forums/"
      },
      {
        "title": "Apple Design Awards",
        "url": "https://developer.apple.com/design/awards/"
      }
    ],
    "hdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2021/10265/4/9BD45E56-F096-4BDD-AAFA-CF90B0501E1B/downloads/wwdc2021-10265_hd.mp4?dl=1",
    "sdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2021/10265/4/9BD45E56-F096-4BDD-AAFA-CF90B0501E1B/downloads/wwdc2021-10265_sd.mp4?dl=1"
  },
  "relatedVideos": [
    {
      "id": "10233",
      "year": "2023",
      "title": "Enhance your app’s audio experience with AirPods",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10233"
    },
    {
      "id": "10143",
      "year": "2021",
      "title": "Explore HLS variants in AVFoundation",
      "url": "https://developer.apple.com/videos/play/wwdc2021/10143"
    },
    {
      "id": "10146",
      "year": "2021",
      "title": "What’s new in AVFoundation",
      "url": "https://developer.apple.com/videos/play/wwdc2021/10146"
    }
  ],
  "extractedAt": "2025-07-18T09:24:12.788Z"
}